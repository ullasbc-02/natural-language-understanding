{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz8I+pM9JLQAo6ReTM6cM3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ullasbc-02/natural-language-understanding/blob/main/hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ],
      "metadata": {
        "id": "igENxW-RtsPJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jzpgB6pNpCgT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Tweets_5K.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "id": "JCNOy-NypEdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fff312-79c7-4f92-f710-d20a6673e0f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   textID     5000 non-null   object\n",
            " 1   text       5000 non-null   object\n",
            " 2   sentiment  5000 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 117.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_tweets = df['text']\n",
        "sentiments = df['sentiment']"
      ],
      "metadata": {
        "id": "a2ToSFOUq0fX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "senti_mapping = {\n",
        "    'negative': -1,\n",
        "    'neutral': 0,\n",
        "    'positive': 1\n",
        "}\n",
        "\n",
        "labels = df['sentiment'].map(senti_mapping).tolist()"
      ],
      "metadata": {
        "id": "XL-xgttsrCep"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_tweets.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "K2g1HqqqrlwQ",
        "outputId": "f5be93e3-7630-431f-dba9-446107d00916"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  I`d have responded, if I were going\n",
              "1        Sooo SAD I will miss you here in San Diego!!!\n",
              "2                            my boss is bullying me...\n",
              "3                       what interview! leave me alone\n",
              "4     Sons of ****, why couldn`t they put them on t...\n",
              "5    http://www.dothebouncy.com/smf - some shameles...\n",
              "6    2am feedings for the baby are fun when he is a...\n",
              "7                                           Soooo high\n",
              "8                                          Both of you\n",
              "9     Journey!? Wow... u just became cooler.  hehe....\n",
              "Name: text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my boss is bullying me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what interview! leave me alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2am feedings for the baby are fun when he is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Soooo high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Both of you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKMYNzErmcV",
        "outputId": "917e6b34-1f4a-4a36-a592-f4f9a19f6adb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, -1, -1, -1, -1, 0, 1, 0, 0, 1, 0, 1, -1, -1, 0, -1, -1, -1, -1, 0, 0, 1, 0, 0, 0, 1, -1, -1, 1, -1, 1, 1, -1, 1, 0, 0, -1, 0, -1, 1, 0, 1, 0, 0, 1, 0, -1, 0, -1, -1, 0, 0, 0, -1, 1, 0, -1, 0, -1, 0, -1, 0, -1, 1, -1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, -1, 0, -1, 0, 1, 1, 0, -1, -1, 1, 0, 0, -1, 1, 1, 0, 0, -1, 0, 1, -1, -1, 0, 1, 1, 0, -1, -1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, -1, -1, 1, 1, 0, 0, 0, -1, -1, -1, 1, 0, 0, 0, 1, 1, 1, -1, -1, 1, 1, 0, 0, 0, -1, 0, -1, -1, -1, -1, 0, -1, 0, 1, 1, 0, 1, -1, 1, -1, 0, 0, 0, -1, 1, -1, 0, 0, -1, 0, -1, 1, 0, 1, 1, 1, 1, -1, 0, 0, -1, -1, 0, -1, 0, 0, 1, 1, -1, 0, 0, 0, -1, 0, -1, 1, 1, 0, -1, -1, 0, -1, 1, 0, 0, -1, -1, 0, 0, -1, -1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, -1, 0, 0, 0, 0, -1, 0, -1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, -1, -1, 0, 0, 0, 1, 0, -1, 0, 0, 1, 0, 0, -1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, -1, -1, 1, -1, 1, 1, 0, -1, 0, -1, 0, -1, 0, 0, 1, -1, -1, 0, 0, 1, 0, 0, 0, 1, 1, -1, 0, 0, 1, 1, -1, 1, -1, 0, 0, 0, -1, -1, 0, -1, -1, 1, -1, 0, 0, 1, -1, 0, -1, 0, 0, 1, 0, -1, -1, 0, 1, -1, -1, -1, 0, -1, 0, 1, 0, 1, 1, -1, 1, 1, -1, 0, -1, -1, -1, -1, 0, -1, -1, 0, 0, 1, 1, 0, 1, 0, 1, 0, -1, 0, -1, 0, -1, 1, 0, -1, 1, 1, 1, 0, -1, 1, 1, 0, 0, 0, 0, 1, 0, -1, 0, 0, -1, 0, 0, -1, -1, -1, -1, 0, 0, 0, -1, 0, 0, 1, 1, -1, 1, 0, 0, 1, 1, 1, -1, 1, 1, 0, 0, 0, 1, 1, 0, 1, -1, -1, -1, 1, -1, 1, -1, 1, 0, 1, -1, 1, -1, 1, -1, 0, 0, 0, 0, 1, 0, 1, 0, -1, 1, 0, 0, -1, 1, -1, -1, -1, -1, 1, 1, 0, 0, 0, 1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 0, -1, 0, 0, -1, 1, -1, -1, -1, -1, 0, 0, -1, 0, -1, -1, -1, 0, -1, -1, 0, 1, -1, 0, -1, 0, 0, 1, -1, -1, 1, 0, 1, 1, 0, -1, 0, -1, 1, 0, -1, -1, -1, 1, 1, 1, 1, 0, 1, 0, 0, -1, 0, -1, 1, 0, 1, -1, -1, 1, 0, -1, 0, -1, -1, -1, 1, -1, -1, 1, 0, 0, -1, 0, 0, 1, 0, -1, -1, 1, 0, 0, 1, 0, 0, -1, -1, 0, 1, -1, 0, 0, 0, -1, 0, -1, -1, -1, -1, 0, 0, 0, 1, -1, 0, 0, 1, 1, 0, -1, -1, 0, -1, -1, -1, 1, 1, 0, -1, 1, 0, 1, 1, 0, -1, -1, 0, 1, -1, -1, 0, -1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, -1, 0, 1, 1, -1, -1, 0, 1, 0, 0, 0, -1, -1, -1, 0, 0, 0, -1, 0, 1, 0, -1, 0, 1, -1, 0, 0, -1, 1, 0, 0, 0, 0, -1, 1, -1, -1, 0, 1, 0, 1, 1, 0, 0, -1, -1, -1, 1, 0, 1, 0, 1, 0, -1, 0, -1, 0, 1, 0, -1, 1, 1, 0, 0, -1, 1, 0, -1, 0, 1, 1, 0, 0, -1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, -1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, -1, 0, -1, -1, -1, 1, 1, 0, 1, -1, -1, -1, 1, 0, 1, 0, -1, 1, -1, -1, 0, 1, -1, 0, 0, 0, 0, -1, 1, -1, 1, 1, 1, 1, 0, 1, -1, -1, 0, 0, 0, 0, 1, 1, -1, 0, 0, -1, 0, 0, 0, 1, 1, -1, 1, 1, 1, 1, 1, 0, 1, -1, 0, 1, 0, -1, 1, -1, 0, 0, 0, -1, 0, 0, 0, -1, -1, 1, 0, 1, 1, -1, -1, -1, 0, 1, 0, 1, -1, 1, -1, 0, -1, -1, 1, 0, -1, 1, 1, 0, 1, -1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, -1, -1, 1, 0, 1, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 1, -1, -1, 0, 1, 0, 0, 0, 0, 0, -1, -1, 1, 0, -1, 1, 0, -1, 0, 0, -1, -1, 0, 0, 1, 0, -1, 1, 1, 1, 1, -1, 1, 1, 0, 0, 0, 1, -1, -1, -1, 1, -1, 0, 0, 1, 0, 1, -1, -1, -1, 0, 1, -1, 0, -1, 1, 0, 1, 1, 1, 0, 1, -1, 1, -1, -1, 1, 0, 1, 1, -1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, -1, -1, 0, 1, 0, -1, 1, 0, -1, 0, 1, 0, 1, 0, -1, 0, 0, 1, 1, 0, -1, -1, 0, 0, 0, -1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, -1, -1, 0, 0, -1, 0, 1, 1, -1, 0, 1, 1, -1, -1, 0, 1, 1, 1, 1, 0, 0, 1, 0, -1, 0, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, -1, 1, -1, -1, -1, 1, -1, 1, 0, 0, 1, -1, 1, -1, 1, 1, 1, 1, -1, 0, 0, 0, 1, 1, -1, 0, 1, 0, 0, 1, 1, 0, 1, 0, -1, 0, 0, -1, 1, -1, 0, 0, 1, 0, 0, -1, 0, -1, 0, -1, 0, 0, 1, 0, 0, 0, 0, -1, 0, 0, -1, 0, 1, 0, 1, 1, 1, 1, -1, 0, -1, 1, -1, 1, -1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 0, 1, 1, 0, -1, 0, -1, 1, 0, 1, 1, 0, -1, 0, 0, 1, -1, 1, 0, -1, 0, 1, 1, 0, -1, 1, -1, 0, 1, 0, 1, 1, 0, 1, -1, 1, 0, -1, 1, 1, 1, 1, 0, 0, 0, 1, 0, -1, -1, 1, -1, -1, 1, 0, -1, 1, 1, 1, 0, 0, 0, -1, 1, 0, 0, 1, -1, 0, 1, 0, 0, -1, 1, 1, 0, -1, 0, -1, 0, -1, 0, 0, 1, -1, -1, 0, 0, 0, -1, 1, 0, 0, -1, 0, 1, -1, 1, 1, -1, 0, 1, 0, 0, -1, -1, 1, 0, 0, -1, -1, 0, 1, 0, 1, 1, -1, -1, 1, 0, 1, -1, 0, -1, -1, 1, 0, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 0, -1, 1, 0, 0, 0, 0, -1, 1, 0, 0, 0, 0, 1, 0, -1, 1, 0, -1, 1, 1, 0, 0, -1, -1, 1, 1, 1, 1, 0, -1, -1, 0, -1, 0, 1, 1, 0, 0, 1, -1, -1, 1, -1, 1, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, -1, -1, 1, 0, -1, 1, 1, -1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, -1, 0, 0, 0, -1, -1, 1, 1, 0, 1, -1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, -1, -1, 0, 0, 0, 1, 0, 0, 0, 0, 1, -1, 1, -1, 1, -1, 0, 0, 0, 1, 0, 0, 1, -1, -1, 1, 1, 0, 1, 1, 0, 0, -1, 0, 0, 0, 1, -1, 0, -1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, -1, 0, 1, -1, 0, 1, -1, 1, 1, 0, -1, 0, -1, 1, -1, 0, 0, -1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, -1, 1, 1, -1, 1, 0, 0, 0, 0, -1, 1, 0, 1, -1, -1, 0, 1, 1, -1, -1, 1, -1, 0, 0, -1, -1, 0, -1, 1, 0, 1, 1, 0, -1, 0, 1, 1, 1, -1, 1, 0, 0, 0, -1, 1, 1, 1, 1, 0, 0, 1, 1, -1, -1, -1, -1, 0, -1, -1, 0, 0, 1, 1, 0, 0, 1, -1, -1, 0, -1, 1, 1, 1, 1, -1, -1, 0, 1, 0, -1, 0, -1, -1, -1, 0, 1, 0, -1, 0, 0, 1, 1, -1, 0, 1, 0, -1, 1, 0, 0, 0, -1, 0, -1, -1, 0, 0, 1, 0, 1, -1, 0, 0, 0, 1, 1, 1, 0, 0, -1, -1, -1, -1, 1, 0, 0, 0, -1, 1, 1, 1, 0, 1, 0, 1, 1, -1, 0, -1, 0, 0, 0, 0, -1, -1, 1, -1, 0, 1, 0, 0, 1, -1, 0, 1, 0, 0, -1, -1, 1, -1, -1, -1, 0, 0, 1, 1, -1, 0, -1, -1, 1, 0, 0, -1, -1, -1, 0, 1, 0, 0, 1, 1, 1, 0, -1, 1, -1, 1, 1, 0, 1, 1, 0, -1, 0, 1, 1, 0, -1, 0, 0, -1, 1, 0, 1, 1, 1, -1, 1, 1, 0, -1, -1, 0, 1, -1, 0, -1, 1, -1, 0, 1, 0, 0, -1, -1, -1, -1, 1, 0, 0, 0, 0, -1, 1, 1, -1, 0, 0, -1, 0, -1, 1, -1, 0, 1, -1, 0, 1, 1, 1, -1, 1, 1, 1, -1, 0, 0, 0, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, 0, 0, -1, -1, 1, -1, 0, 1, -1, 0, -1, 1, -1, 0, 0, 1, -1, 0, 1, -1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, -1, 0, -1, 0, 1, 0, 1, 0, 0, -1, 0, -1, 1, 0, -1, 1, 0, 0, 1, 0, 1, -1, -1, 0, 0, 0, 1, 0, -1, 0, 1, 1, 0, 0, 0, 0, -1, -1, 0, -1, 1, 1, 0, -1, 0, -1, 0, -1, 1, -1, 0, 1, -1, 0, -1, 1, 0, -1, -1, 1, 0, 1, 1, 1, 1, -1, 0, -1, -1, 0, 1, 0, 0, -1, 0, 1, -1, 1, 1, 0, 1, -1, 0, -1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, -1, 1, 0, 1, 0, 0, 1, 1, 1, -1, 0, -1, 0, -1, 1, -1, 1, 1, -1, 0, 1, 1, 0, -1, 1, 1, 0, -1, 1, 1, 1, -1, -1, -1, -1, 0, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, -1, -1, 0, 1, -1, -1, -1, 0, 1, 1, 0, -1, 0, 1, -1, 0, -1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, -1, -1, 0, -1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, -1, 1, 0, -1, -1, -1, -1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, -1, 1, -1, 0, -1, 1, 0, 1, 0, 1, 1, 1, -1, 1, 1, -1, 0, 0, 0, -1, -1, -1, -1, 0, 1, 0, -1, 0, -1, -1, 0, 0, 0, -1, 1, 1, -1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, -1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, -1, 1, -1, 1, -1, 0, 1, 0, 1, 0, -1, 0, -1, -1, 0, 1, 0, 1, 1, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, 0, 1, 0, 0, 1, -1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, -1, -1, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, 1, 0, 0, 0, -1, 1, 0, 1, 0, -1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, -1, 0, 0, -1, 0, -1, 1, -1, 0, 1, -1, -1, -1, 1, 0, -1, 0, 0, 0, 1, -1, 1, 1, -1, 0, 1, 0, -1, 1, -1, -1, 1, 1, 0, 1, 0, -1, 0, 0, 0, 0, 1, -1, -1, -1, 0, -1, 0, 1, 0, 1, -1, 0, 0, -1, 1, -1, -1, 1, -1, 0, 0, 1, 0, 1, 1, -1, 0, 1, -1, 0, 0, 0, 1, 0, 1, -1, 0, 0, 0, -1, -1, 1, 0, -1, 1, 0, 0, -1, 0, 0, 1, 1, 0, 1, 1, 1, 0, -1, 0, 0, -1, 0, 1, -1, 1, -1, 0, 1, 0, -1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, -1, 0, 0, 0, 0, 0, 0, -1, 1, 0, -1, -1, -1, 0, 1, -1, -1, 0, 0, 1, 0, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, 0, 0, -1, 0, 1, -1, 0, -1, -1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, -1, 1, 1, 1, 0, -1, 0, 1, 0, 1, 0, 0, 1, 1, -1, 1, 1, 0, 0, -1, 1, -1, -1, 1, 0, -1, 0, 0, 0, -1, 0, 0, 1, 0, 0, -1, 1, 1, 0, -1, 0, -1, 0, 0, 0, -1, -1, 1, 0, -1, 1, 0, 0, 0, 1, -1, 0, 0, 0, -1, -1, -1, -1, 1, 0, -1, 1, 1, 1, 0, 0, 0, -1, 1, 1, 0, 0, -1, 0, 0, 1, 0, -1, 0, -1, 0, 0, 0, 0, 1, 0, -1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, -1, -1, 0, 0, -1, 1, 1, -1, -1, 0, -1, 0, -1, 0, 0, 0, 0, -1, -1, 0, 1, 0, 1, -1, -1, -1, 0, 0, -1, -1, 0, 1, 1, 1, 1, 1, -1, 0, 1, -1, -1, 0, 0, 1, 0, 1, 0, -1, 0, 1, 0, 1, -1, 0, -1, -1, 0, -1, 1, 0, 1, 0, -1, 0, 1, -1, 0, 0, 1, -1, 0, 0, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0, -1, 0, 0, 1, 1, 0, 1, 1, 0, -1, 1, 0, -1, -1, -1, 1, -1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, -1, -1, 1, 0, 1, 1, 1, 1, -1, 1, 0, 0, 0, 0, -1, 0, 1, 1, -1, 1, 0, 0, -1, -1, 1, 0, -1, 1, 1, -1, 0, 1, -1, 0, 1, 0, 0, -1, 0, 0, 1, -1, -1, -1, 0, 0, -1, 1, -1, 1, 0, 0, 1, -1, 0, -1, 1, -1, 0, 0, 0, 1, 0, -1, 0, 0, -1, -1, 1, 0, 1, 1, 0, 0, 0, 0, -1, 1, -1, 0, 1, 1, -1, 0, 0, 1, -1, 0, 0, 1, 0, 1, -1, 1, 1, -1, 0, -1, 0, -1, 1, 0, 0, -1, 1, 0, -1, -1, 0, 1, 0, 0, 1, -1, -1, 1, 0, 1, -1, -1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, -1, -1, -1, 0, 0, 0, -1, 0, 1, 1, -1, 1, 0, 0, 0, 0, 0, 1, -1, 1, 0, 0, -1, 0, 0, -1, 0, -1, -1, 1, 0, 0, -1, -1, 0, 1, 1, 0, 1, 1, -1, -1, -1, 1, 1, -1, 1, 0, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 0, 0, 1, 0, 1, 1, -1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, -1, 1, 0, 0, -1, -1, 0, -1, 0, 0, 1, -1, 0, 1, 0, 1, 1, 1, 1, -1, 1, 0, -1, 0, 0, 0, 1, 0, -1, -1, -1, 0, -1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, -1, 1, 1, -1, 0, 0, 0, -1, -1, -1, 0, 1, 0, -1, -1, -1, 0, -1, -1, 0, -1, 0, -1, 0, -1, 0, -1, 1, 0, -1, -1, 1, -1, 1, 0, -1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, -1, 1, 0, 1, 0, 0, -1, 1, 0, -1, 0, 1, 1, 0, -1, -1, 1, -1, -1, 0, 1, 1, 1, 1, -1, 1, 1, 0, 1, -1, -1, 0, 1, -1, 0, -1, -1, -1, 0, 0, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, 0, 1, 1, -1, 0, 0, 0, 1, 0, -1, 0, 1, 0, 0, 1, 1, -1, 1, 0, 0, 1, 0, 0, 0, 1, -1, 1, 1, -1, 1, -1, 0, 1, 1, -1, -1, 0, 1, -1, 0, 0, 1, 0, 1, 0, 0, -1, 1, 0, 1, -1, 0, -1, 1, 1, -1, 0, 0, 0, 1, 1, 1, 0, -1, -1, -1, 1, 1, 0, 1, -1, 0, 0, 1, 0, 0, 0, -1, -1, 1, 1, 0, -1, 1, 0, -1, -1, -1, -1, -1, 0, 0, 0, 1, -1, 1, -1, -1, 0, 1, 1, -1, -1, 1, -1, 0, 1, 0, 1, -1, 0, 0, 1, 0, 0, -1, 0, 0, -1, 1, 1, 0, -1, 0, 1, 0, -1, 1, 0, 1, -1, -1, 0, -1, 0, 0, 0, 1, 1, -1, 0, -1, 0, -1, 0, 1, -1, 1, 0, 1, 1, 1, 1, 0, 0, -1, 0, -1, -1, -1, -1, -1, 0, 1, 0, 1, 0, 0, -1, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 0, 1, 1, -1, 1, 1, 1, 1, 0, 1, -1, 0, 1, 0, 0, 1, -1, 0, 1, -1, 1, 0, -1, 0, 1, -1, 1, 1, 0, 1, 0, 0, 1, -1, -1, -1, -1, 0, 0, 0, 0, -1, -1, 0, -1, 0, 0, 0, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, 0, 1, 1, 0, 1, 0, 0, 0, 0, -1, 0, 0, -1, -1, 0, -1, 0, 0, 1, -1, 1, 1, 0, -1, -1, -1, -1, -1, 0, 1, 1, 1, 1, 0, -1, -1, 0, -1, 0, 1, 1, 0, -1, 0, 0, 1, 0, -1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, -1, 0, 0, 1, -1, 0, -1, 1, 1, 0, 1, 0, 1, -1, 0, 1, 1, 1, 1, 0, 0, 0, 0, -1, -1, 0, 1, -1, 1, -1, -1, 1, -1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, -1, -1, -1, 0, 0, 1, -1, -1, -1, 0, 0, 0, 1, 1, -1, 0, -1, 1, -1, 1, -1, 0, -1, 0, -1, 1, 0, 0, 0, 0, 1, 1, -1, 1, -1, 0, -1, 0, 1, 0, -1, 1, 1, 0, 0, -1, -1, -1, -1, -1, 1, 0, 0, -1, 0, 1, 0, -1, 0, 1, 0, 0, 1, -1, 1, 0, 1, 1, 1, 0, -1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, -1, 0, 1, 0, 0, -1, 1, 1, 0, -1, 1, 0, 1, 0, -1, 0, -1, -1, -1, 0, -1, 1, 0, 0, 1, 0, 0, 1, -1, -1, 0, 0, 0, -1, -1, -1, 1, -1, -1, 0, -1, 1, -1, -1, -1, 0, 0, -1, 0, 1, 1, 1, -1, 0, 0, 0, -1, 0, -1, 0, -1, 1, -1, 0, 1, 0, -1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, -1, 0, 0, -1, 0, 1, 0, -1, 0, 1, -1, 1, -1, 1, -1, 1, 1, 1, 0, 1, 0, -1, 1, 0, -1, 1, 0, 1, 1, -1, 0, -1, 0, 0, 0, 1, 0, -1, -1, 1, -1, 0, 1, 1, 0, 1, 1, -1, 1, 0, -1, 0, 0, 1, 1, -1, 1, -1, 0, -1, 1, 0, 0, 0, 1, 0, 0, 0, 0, -1, 0, 1, 0, 1, 1, 0, -1, 1, -1, -1, 0, -1, 0, -1, -1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, -1, -1, 1, 0, -1, 0, 0, 1, 1, -1, 0, -1, 0, -1, 1, 1, 0, 0, 1, -1, 0, -1, 1, 0, 0, -1, 0, 0, -1, 1, 1, 1, 1, -1, -1, 1, 0, 1, 0, 1, 1, -1, 1, 0, -1, -1, 0, -1, -1, -1, -1, -1, 0, 1, 1, 0, 1, 1, 1, -1, 0, 0, -1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, -1, 0, -1, 1, 1, -1, 1, 1, 1, 0, 0, 0, 0, 0, -1, 1, 1, 1, 0, -1, -1, 0, 0, -1, -1, 0, -1, -1, -1, -1, 0, 1, 0, -1, -1, 0, -1, 1, 1, 1, 1, 1, 0, 0, 0, 0, -1, 0, -1, 0, 1, 0, 0, 1, -1, 1, 0, 0, -1, -1, 1, 0, -1, 1, 0, -1, 0, 1, 0, -1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, -1, -1, -1, 1, 0, -1, -1, 0, -1, -1, -1, 0, 1, 0, 1, 1, -1, 0, 1, 0, 1, -1, 1, -1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, -1, -1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, -1, -1, -1, 0, 1, -1, 0, 0, 1, 0, 0, 0, 1, -1, -1, 0, 1, 0, -1, 0, -1, -1, 0, -1, 0, 0, -1, -1, -1, -1, 0, 1, -1, -1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, -1, 1, 0, 0, -1, 0, 1, 0, -1, -1, -1, 1, 0, 1, 0, 1, 0, -1, 0, 1, 0, 0, -1, 1, 1, 0, -1, 0, 1, 1, 1, -1, 0, 1, 1, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 1, 0, 0, 1, 0, 0, 1, 1, -1, 0, 1, 0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0, 1, -1, -1, 0, 1, 1, -1, 1, -1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, -1, 1, 0, 0, 0, 0, -1, 1, 1, 1, 1, 1, 0, -1, 1, 0, -1, -1, -1, 1, 1, 0, 1, 0, 1, -1, -1, 0, 1, -1, 0, -1, 0, 0, -1, 0, -1, 1, 1, -1, 1, 0, -1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, -1, 0, 1, 1, 0, 1, 1, 1, -1, -1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, -1, 0, 0, 0, 1, 1, 1, 1, 0, -1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, -1, -1, -1, 0, 0, 1, 0, 0, 1, -1, -1, 0, 1, 1, 0, -1, 0, 0, -1, 0, 1, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 1, 0, 0, 1, 1, 1, -1, -1, 0, 0, 1, 0, -1, 0, 1, -1, -1, 1, 1, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, 1, 0, 1, -1, 0, 0, -1, 1, 1, 0, 1, -1, 1, 0, -1, -1, 1, 1, 1, 1, -1, 0, -1, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, -1, 1, -1, -1, -1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, -1, 0, 1, 0, -1, -1, 0, -1, 0, -1, 0, 1, 1, 0, 0, -1, 1, 0, 1, -1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, -1, 0, -1, -1, 1, 1, -1, -1, 0, -1, 0, -1, 1, 1, 0, 1, -1, -1, 1, -1, 1, 0, -1, -1, 0, -1, 0, -1, -1, 0, 1, 0, 0, 1, 1, 0, -1, -1, -1, 1, 1, 1, 0, 1, -1, 1, -1, 0, 0, 1, -1, 1, 0, 0, -1, 0, -1, 1, 1, 0, 0, 1, -1, 0, 1, 0, 0, 0, -1, 0, 0, 1, 1, 0, 0, 0, -1, -1, 1, -1, 0, 0, 0, -1, 0, 1, 0, -1, 1, 1, 1, 0, 1, 1, 0, 0, -1, 0, -1, -1, -1, 1, 0, 0, 0, 0, -1, -1, 0, 0, 0, -1, 0, 0, 0, -1, 0, -1, 0, 1, -1, 0, 1, 0, 1, 1, -1, -1, 1, 1, 1, 0, 1, -1, 0, 0, 0, 1, 1, 0, 1, -1, 1, 1, 0, -1, 0, -1, 0, 1, 1, 1, -1, 0, -1, 0, 0, -1, 1, 0, 1, 1, 0, -1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, -1, 0, 0, -1, -1, 0, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 1, 0, -1, 1, -1, -1, 0, 1, 1, 0, 1, -1, 0, -1, -1, 0, 0, -1, -1, 1, 0, -1, -1, 1, 1, 0, 0, 1, -1, -1, 1, 1, 1, -1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, -1, 1, 1, 0, 0, -1, -1, 0, 0, -1, 0, 1, -1, -1, 0, -1, -1, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 1, 0, -1, 0, -1, 1, -1, -1, 0, 0, -1, 0, -1, -1, 1, 0, -1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, -1, 0, 0, 0, 0, 1, 0, -1, 1, 0, -1, -1, 1, -1, 0, -1, 1, -1, 1, 0, 1, 0, 0, 0, 0, 0, -1, 1, 1, 1, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 1, 0, 0, -1, 0, -1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, -1, 0, 1, 1, 0, -1, -1, -1, -1, 0, -1, 0, 0, 1, -1, 0, -1, 0, 1, 1, 1, 0, -1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, -1, -1, 1, 1, 1, -1, 1, 0, 1, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 1, 0, -1, 1, 0, 1, 0, -1, 1, 0, 0, 1, -1, 1, 0, -1, -1, 0, 1, 0, -1, -1, 1, -1, -1, 0, 1, -1, -1, 1, 0, 1, -1, 1, -1, 1, 1, 1, 0, -1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 1, 0, -1, 1, -1, 0, 1, -1, 0, 1, 0, 1, 0, -1, 1, -1, 0, 1, 0, 1, -1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, -1, 1, -1, 1, -1, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0, 1, 0, 0, 0, 0, -1, 1, 1, 1, 0, 0, -1, 0, 0, 0, -1, -1, 1, 1, -1, 0, 0, 0, 0, 1, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, -1, 1, 1, 0, -1, 0, 0, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 0, -1, 1, -1, -1, 0, 0, 1, -1, 1, 0, -1, -1, 1, 1, 1, 0, 1, 1, -1, 0, 0, 1, -1, -1, 1, 0, 0, 1, -1, 1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 1, 0, 1, 0, 0, 0, -1, -1, 0, 0, 1, -1, 1, 0, 0, 0, 0, 1, -1, 0, 1, 0, 0, 1, 1, -1, 0, -1, 0, 1, 0, -1, 0, 0, -1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, -1, 0, -1, -1, 1, -1, 0, 0, -1, 0, -1, 1, 1, 1, 0, 1, 1, 0, -1, 1, 0, 1, -1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, -1, 1, 0, 1, -1, 1, 0, -1, 1, -1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, -1, 0, 1, 0, 1, 1, 0, 0, 0, -1, -1, 0, -1, 1, 0, 0, 1, 0, 0, 0, -1, 1, 1, 0, -1, 1, -1, 0, 0, -1, 0, 0, -1, -1, 1, 0, 1, 0, 1, -1, 0, 1, 1, 1, 0, 0, -1, 0, 1, -1, 0, -1, 1, 1, 0, 1, 1, -1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, -1, -1, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 1, 0, 0, 0, -1, -1, 0, 1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 0, 0, 0, -1, 1, 0, 1, -1, 1, 0, 1, 0, 0, 0, -1, 1, -1, 0, 1, 1, 1, 0, -1, -1, -1, -1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, -1, -1, 0, 0, -1, -1, 1, -1, 0, 0, 1, 0, -1, -1, -1, 0, 1, 0, 0, -1, 0, -1, -1, 1, 1, -1, 1, 0, 0, 1, -1, 1, -1, 0, 0, -1, 1, 0, 0, 1, -1, -1, 1, 0, 0, -1, 0, -1, -1, 0, 1, 1, 0, 1, -1, 1, 1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 0, 0, 1, 0, 1, 0, -1, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basic_preproc_tweets = raw_tweets.str.strip().str.split(\" \")\n",
        "\n",
        "basic_preproc_tweets.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "dI8SqAqGr7Uu",
        "outputId": "ede16ca0-ecef-4415-95e2-7a2f287e9249"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          [I`d, have, responded,, if, I, were, going]\n",
              "1    [Sooo, SAD, I, will, miss, you, here, in, San,...\n",
              "2                      [my, boss, is, bullying, me...]\n",
              "3                 [what, interview!, leave, me, alone]\n",
              "4    [Sons, of, ****,, why, couldn`t, they, put, th...\n",
              "5    [http://www.dothebouncy.com/smf, -, some, sham...\n",
              "6    [2am, feedings, for, the, baby, are, fun, when...\n",
              "7                                        [Soooo, high]\n",
              "8                                      [Both, of, you]\n",
              "9    [Journey!?, Wow..., u, just, became, cooler., ...\n",
              "Name: text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[I`d, have, responded,, if, I, were, going]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Sooo, SAD, I, will, miss, you, here, in, San,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[my, boss, is, bullying, me...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[what, interview!, leave, me, alone]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Sons, of, ****,, why, couldn`t, they, put, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[http://www.dothebouncy.com/smf, -, some, sham...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[2am, feedings, for, the, baby, are, fun, when...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[Soooo, high]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[Both, of, you]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[Journey!?, Wow..., u, just, became, cooler., ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basic_preproc_bow = basic_preproc_tweets.apply(lambda x: pd.Series(x).value_counts()).fillna(0)"
      ],
      "metadata": {
        "id": "ac-5TCzeshEU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_preproc_bow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvd81P_jw20l",
        "outputId": "b8f54603-1e7a-4f6a-90f1-c2b80aae7ad3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 15122)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(basic_preproc_bow)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roArgJIZt7dE",
        "outputId": "e61fd974-342f-4e10-9a31-403095866be5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      I`d  have  responded,   if    I  were  going  Sooo  SAD  will  ...  \\\n",
            "0     1.0   1.0         1.0  1.0  1.0   1.0    1.0   0.0  0.0   0.0  ...   \n",
            "1     0.0   0.0         0.0  0.0  1.0   0.0    0.0   1.0  1.0   1.0  ...   \n",
            "2     0.0   0.0         0.0  0.0  0.0   0.0    0.0   0.0  0.0   0.0  ...   \n",
            "3     0.0   0.0         0.0  0.0  0.0   0.0    0.0   0.0  0.0   0.0  ...   \n",
            "4     0.0   0.0         0.0  0.0  0.0   0.0    0.0   0.0  0.0   0.0  ...   \n",
            "...   ...   ...         ...  ...  ...   ...    ...   ...  ...   ...  ...   \n",
            "4995  0.0   0.0         0.0  0.0  0.0   0.0    0.0   0.0  0.0   0.0  ...   \n",
            "4996  0.0   0.0         0.0  0.0  0.0   0.0    0.0   0.0  0.0   0.0  ...   \n",
            "4997  0.0   0.0         0.0  0.0  0.0   0.0    0.0   0.0  0.0   0.0  ...   \n",
            "4998  0.0   0.0         0.0  0.0  1.0   0.0    0.0   0.0  0.0   0.0  ...   \n",
            "4999  0.0   1.0         0.0  0.0  0.0   0.0    0.0   1.0  0.0   0.0  ...   \n",
            "\n",
            "      reviews  scrapbook.  fiasco  wrapped  midterms   =(  7th  headache-all  \\\n",
            "0         0.0         0.0     0.0      0.0       0.0  0.0  0.0           0.0   \n",
            "1         0.0         0.0     0.0      0.0       0.0  0.0  0.0           0.0   \n",
            "2         0.0         0.0     0.0      0.0       0.0  0.0  0.0           0.0   \n",
            "3         0.0         0.0     0.0      0.0       0.0  0.0  0.0           0.0   \n",
            "4         0.0         0.0     0.0      0.0       0.0  0.0  0.0           0.0   \n",
            "...       ...         ...     ...      ...       ...  ...  ...           ...   \n",
            "4995      0.0         0.0     0.0      0.0       0.0  0.0  0.0           0.0   \n",
            "4996      1.0         1.0     0.0      0.0       0.0  0.0  0.0           0.0   \n",
            "4997      0.0         0.0     1.0      1.0       1.0  1.0  0.0           0.0   \n",
            "4998      0.0         0.0     0.0      0.0       0.0  0.0  1.0           0.0   \n",
            "4999      0.0         0.0     0.0      0.0       0.0  0.0  0.0           1.0   \n",
            "\n",
            "      inflicted  course!  \n",
            "0           0.0      0.0  \n",
            "1           0.0      0.0  \n",
            "2           0.0      0.0  \n",
            "3           0.0      0.0  \n",
            "4           0.0      0.0  \n",
            "...         ...      ...  \n",
            "4995        0.0      0.0  \n",
            "4996        0.0      0.0  \n",
            "4997        0.0      0.0  \n",
            "4998        0.0      0.0  \n",
            "4999        1.0      1.0  \n",
            "\n",
            "[5000 rows x 15122 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(basic_preproc_bow.iloc[1460, 1460])\n",
        "print(basic_preproc_bow.columns[1460])\n",
        "#1460 document does not contain word \"300th\", so the value is 0 otherwise it will be 1.1\n",
        "#1460the column signifies the word \"300th\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6vd-tANv_xm",
        "outputId": "530039a1-d91e-4e6d-8e82-caad9e205c8c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "300th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets_train, Tweets_test, Labels_train, Labels_test = train_test_split(basic_preproc_bow, labels, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "9vxhz32hu9ZA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ],
      "metadata": {
        "id": "wCBEcDlaxbBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_nb = MultinomialNB(alpha=1.0)\n",
        "\n",
        "model_nb.fit(Tweets_train, Labels_train)\n",
        "\n",
        "nb_predictions = model_nb.predict(Tweets_test)\n",
        "nb_accuracy = accuracy_score(Labels_test, nb_predictions)\n",
        "print(\"Naive Bayes Accuracy:\",nb_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D6lC14C07I9",
        "outputId": "3420839d-7aaf-4b81-b874-3d6b483a9cd6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "baseline_model = DummyClassifier(strategy=\"most_frequent\")\n",
        "baseline_model.fit(Tweets_train, Labels_train)\n",
        "\n",
        "\n",
        "baseline_predictions = baseline_model.predict(Tweets_test)\n",
        "baseline_accuracy = accuracy_score(Labels_test, baseline_predictions)\n",
        "\n",
        "print(\"Most Frequent Baseline Accuracy: \", baseline_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQxfneOpwqrv",
        "outputId": "e2e12d1a-2867-475f-ca57-8a02acedfc41"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Frequent Baseline Accuracy:  0.427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3"
      ],
      "metadata": {
        "id": "9YuAvSYr51eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_reg = LogisticRegression(max_iter=200)\n",
        "\n",
        "model_reg.fit(Tweets_train, Labels_train)\n",
        "reg_predictions = model_reg.predict(Tweets_test)\n",
        "reg_accuracy = accuracy_score(Labels_test, reg_predictions)\n",
        "print(\"Logistic Regression Accuracy:\",reg_accuracy)\n",
        "\n",
        "#Model is slightly better than Naive Bayes"
      ],
      "metadata": {
        "id": "N0vBO4uByutU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143b84fb-d4ca-4907-caee-8d6b65d19386"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_reg.coef_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DPglbjt-jHT",
        "outputId": "21978fe5-8a92-40b5-ca00-fd5c5440dbeb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 15122)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features = Tweets_train.shape[1]\n",
        "#(bias+features) * class\n",
        "total_parameters = (features + 1) * 3\n",
        "\n",
        "print(\"Number of features:\", features)\n",
        "\n",
        "print(\"parameters in the model: \", total_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sfp8klo6iyN",
        "outputId": "db1f4be4-c5be-446c-bdf2-36742224648d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 15122\n",
            "parameters in the model:  45369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4\n"
      ],
      "metadata": {
        "id": "ddV73cIU-dNV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "16QCUY6L9snn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f11f426f"
      },
      "source": [
        "# Task\n",
        "The task is to improve the sentiment analysis model for the `Tweets_5K.csv` dataset by:\n",
        "1. Pre-processing the tweet text to remove URLs, user mentions, and hashtags.\n",
        "2. Replacing the existing Bag-of-Words vectorization with TF-IDF vectorization.\n",
        "3. Retraining the Logistic Regression model with the new TF-IDF features and evaluating its performance.\n",
        "4. Comparing the new model's accuracy against previous models (Naive Bayes, baseline, and the initial Logistic Regression model) and explaining the results.\n",
        "5. Analyzing misclassified tweets from the best-performing model to identify error patterns and providing examples.\n",
        "6. Suggesting further improvements based on the misclassification analysis.\n",
        "7. Finally, summarize the pre-processing, feature engineering, model performance, misclassification insights, and future recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "026c986b"
      },
      "source": [
        "## Pre-process Tweets (Remove URLs, Mentions, Hashtags)\n",
        "\n",
        "### Subtask:\n",
        "Clean the raw tweet text by removing URLs, user mentions (e.g., @username), and hashtags (e.g., #topic) using regular expressions. This will create a cleaner text input for vectorization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15b30aca"
      },
      "source": [
        "**Reasoning**:\n",
        "To clean the tweet text, I need to import the `re` module for regular expressions and define a function to remove URLs, mentions, and hashtags. Then, I will apply this function to the `raw_tweets` Series.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a8e956f",
        "outputId": "93fac250-b0a8-4b17-a784-376c0ee50d73"
      },
      "source": [
        "#I used URls, hashtags and mentions because on high level I see too much of these in dataset, removing them will help creating valuable vocab\n",
        "def process_tweet(tweet):\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "    tweet = re.sub(r'#\\w+', '', tweet)\n",
        "    return tweet\n",
        "\n",
        "cleaned_tweets = raw_tweets.apply(process_tweet)\n",
        "\n",
        "\n",
        "print('Original tweet example where cleaning might apply:')\n",
        "print(raw_tweets.loc[5]) # This tweet contains a URL\n",
        "print('Cleaned tweet example:')\n",
        "print(cleaned_tweets.loc[5])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tweet example where cleaning might apply:\n",
            "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n",
            "Cleaned tweet example:\n",
            " - some shameless plugging for the best Rangers forum on earth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b58a2e36",
        "outputId": "50f1e9da-2343-4d53-f032-23f0c7532f7e"
      },
      "source": [
        "Tweets_train_tfidf, Tweets_test_tfidf, Labels_train_tfidf, Labels_test_tfidf = train_test_split(tfidf_df, labels, test_size=0.2, shuffle=False)\n",
        "\n",
        "model_reg_tfidf = LogisticRegression(max_iter=200)\n",
        "model_reg_tfidf.fit(Tweets_train_tfidf, Labels_train_tfidf)\n",
        "\n",
        "reg_predictions_tfidf = model_reg_tfidf.predict(Tweets_test_tfidf)\n",
        "reg_accuracy_tfidf = accuracy_score(Labels_test_tfidf, reg_predictions_tfidf)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Accuracy with TF-IDF:\", reg_accuracy_tfidf)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy with TF-IDF: 0.611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21a19dae",
        "outputId": "b5f3abcc-ef4d-4a85-d5f2-0f0adf7240f8"
      },
      "source": [
        "\n",
        "misclassified_indices = np.where(reg_predictions_tfidf != Labels_test_tfidf)[0]\n",
        "\n",
        "print(\"wrongly predicted tweets by Logistic Regression (TF-IDF): \",len(misclassified_indices))\n",
        "\n",
        "\n",
        "print(\"Examples of misclassified tweets:\\n\")\n",
        "num_examples = min(10, len(misclassified_indices))\n",
        "\n",
        "for i in range(num_examples):\n",
        "    idx = misclassified_indices[i]\n",
        "\n",
        "    original_df_index = Tweets_test_tfidf.index[idx]\n",
        "\n",
        "    print(\"Tweet: :\",cleaned_tweets.loc[original_df_index])\n",
        "    print(\"True Sentiment: :\",Labels_test_tfidf[idx])\n",
        "    print(\"Predicted Sentiment: :\",reg_predictions_tfidf[idx])\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wrongly predicted tweets by Logistic Regression (TF-IDF):  389\n",
            "Examples of misclassified tweets:\n",
            "\n",
            "Tweet: : Glad I went out, glad I didn`t leave early, and glad to be afterpartying it up @ Beth`s  I`m back!\n",
            "True Sentiment: : 1\n",
            "Predicted Sentiment: : 0\n",
            "\n",
            "\n",
            "Tweet: : is texting\n",
            "True Sentiment: : 0\n",
            "Predicted Sentiment: : -1\n",
            "\n",
            "\n",
            "Tweet: : on my way to school of my last friday of high school ever!  and i don`t even get to see holly Gabbie and hannah\n",
            "True Sentiment: : -1\n",
            "Predicted Sentiment: : 0\n",
            "\n",
            "\n",
            "Tweet: :  i cant get through\n",
            "True Sentiment: : -1\n",
            "Predicted Sentiment: : 0\n",
            "\n",
            "\n",
            "Tweet: : no clubs...no parties...ive spent my friday and saturday night workin on music and am quit content\n",
            "True Sentiment: : 0\n",
            "Predicted Sentiment: : -1\n",
            "\n",
            "\n",
            "Tweet: : Whaaaat a strong rain just came over us here in Santa Clara. I wish I could sleep but I got to attend to an important meeting\n",
            "True Sentiment: : -1\n",
            "Predicted Sentiment: : 0\n",
            "\n",
            "\n",
            "Tweet: : Won a gps at post prom\n",
            "True Sentiment: : 1\n",
            "Predicted Sentiment: : 0\n",
            "\n",
            "\n",
            "Tweet: : Watching one of my fav movies Sparkle  + go get food later!\n",
            "True Sentiment: : 1\n",
            "Predicted Sentiment: : 0\n",
            "\n",
            "\n",
            "Tweet: :  Hey, that`s my Bug! And my martini glasses . . .\n",
            "True Sentiment: : 0\n",
            "Predicted Sentiment: : -1\n",
            "\n",
            "\n",
            "Tweet: :  rlly dead?  Descanse em paz...   \n",
            "True Sentiment: : -1\n",
            "Predicted Sentiment: : 0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DOmain specific lexicons should be used because most of the social media texts are short form(em, ngl, op), consists of lot of emojis, different linguistic pattern"
      ],
      "metadata": {
        "id": "r9b6AawpGKZS"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOmain specific lexicons should be used because most of the social media texts are short form(em, ngl, op), consists of lot of emojis,  different linguistic pattern sometimes it's difficult to even read and hardly makes sense\n",
        "\n",
        "General-purpose TF-IDF might miss the specific nuances and evolving vocabulary used in tweets, where words can have different sentiment connotations than in formal text."
      ],
      "metadata": {
        "id": "cjzwnrxFGiBi"
      }
    }
  ]
}